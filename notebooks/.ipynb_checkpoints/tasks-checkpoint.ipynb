{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a6861b",
   "metadata": {},
   "source": [
    "# SuperGLUE Task formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c94e05",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ada30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"facebook/opt-125m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, padding_side='left',)\n",
    "\n",
    "def read_json(filepath: str) -> dict:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def read_jsonl(filepath: str) -> dict:\n",
    "    data = []\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            example = json.loads(line)\n",
    "            data.append(example)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"BoolQ\", \"CB\", \"COPA\", \"MultiRC\", \"ReCoRD\", \"RTE\", \"WiC\", \"WSC\"]\n",
    "data = {}\n",
    "for task_name in tasks:\n",
    "    path = os.path.join(\"/nethome/dhe83/mice/data\", task_name)\n",
    "    task = read_jsonl(os.path.join(path, \"val.jsonl\"))\n",
    "    task = {x['idx']: x for x in task}\n",
    "    data[task_name] = task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8691b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_score(model, prompts, labels):\n",
    "#     prompt_tokens = tokenizer(prompts, padding=True, return_tensors=\"pt\", return_attention_mask=True).to(\"cuda:0\")\n",
    "#     pad_length = prompt_tokens.input_ids.shape[-1]\n",
    "#     labels = tokenizer(labels, padding=\"max_length\", max_length=pad_length, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "#     labels_mask = labels.attention_mask\n",
    "# #     print(\"prompt_tokens\", prompt_tokens)\n",
    "# #     print(\"labels_mask\", labels_mask)\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(**prompt_tokens).logits\n",
    "        \n",
    "# #     print(\"logits\", logits)\n",
    "    \n",
    "# #     print(prompt_tokens.input_ids)\n",
    "\n",
    "#     sequence_logits = logits.log_softmax(-1).gather(-1, prompt_tokens.input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "# #     print(\"sequence_logits\", sequence_logits)\n",
    "#     labels_logits = labels_mask * sequence_logits\n",
    "# #     print(\"labels_logits\", labels_logits)\n",
    "#     log_probs = labels_logits.sum(-1).to(\"cpu\")\n",
    "#     return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a7cec",
   "metadata": {},
   "source": [
    "## In-Context Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186309e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = random.sample(sorted(data), k=400)s\n",
    "train = {k: data[k] for k in t[:200]}\n",
    "test = {k: data[k] for k in t[200:]}\n",
    "\n",
    "prompt_map = {k: [tuple(random.sample(sorted(train), k=1)) for x in range(1)] for k in test.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe71710",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "raw = {}\n",
    "for test_id, train_ids in tqdm(prompt_map.items()):\n",
    "    test = data[test_id]\n",
    "    prompts = []\n",
    "    labels = []\n",
    "    for pair in train_ids:\n",
    "        demonstrations = [data[i] for i in pair]\n",
    "        p, l = COPA_few_shot(demonstrations, test)\n",
    "        prompts.append(p)\n",
    "        labels.append(l)\n",
    "                \n",
    "    prompts =[prompt for pair in prompts for prompt in pair]\n",
    "    labels =[label for pair in labels for label in pair]\n",
    "    log_probs = batch_score(model, prompts, labels)\n",
    "    \n",
    "    log_probs = log_probs.view(-1, 2)\n",
    "    preds = log_probs.argmax(-1)\n",
    "    \n",
    "    pred = 0\n",
    "    if preds.sum(-1) > preds.shape[0] / 2:\n",
    "        pred = 1\n",
    "    results[test_id] = pred\n",
    "    raw[test_id] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea182431",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for id, pred in results.items():\n",
    "    if data[id]['label'] == pred:\n",
    "        correct+=1\n",
    "    total+=1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd504b0c",
   "metadata": {},
   "source": [
    "## Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddc6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, padding_side='left',pad_token=\"-\")\n",
    "results = {}\n",
    "raw = {}\n",
    "total = 0\n",
    "correct = 0\n",
    "for test_id, ex in tqdm(data.items()):\n",
    "    prompts, labels = COPA_few_shot([], ex)\n",
    "    \n",
    "    print(\"prompts\", prompts)\n",
    "#     print(\"labels\", labels)\n",
    "          \n",
    "    log_probs = batch_score(model, prompts, labels)\n",
    "    print(\"log_probs, log_probs\")\n",
    "    log_probs = log_probs.view(-1, 2)\n",
    "    print(\"viewed log_probs\", log_probs)\n",
    "    pred = log_probs.argmax(-1)\n",
    "    print(\"pred\", pred)\n",
    "    \n",
    "    if pred.item() == ex['label']:\n",
    "#         print(\"pred.item()\", pred.item())\n",
    "#         print(\"label\", ex['label'])\n",
    "        correct +=1\n",
    "    total+=1\n",
    "            \n",
    "    results[test_id] = pred.item()\n",
    "    \n",
    "#     print(log_probs)\n",
    "#     break\n",
    "\n",
    "    \n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf041e",
   "metadata": {},
   "source": [
    "## BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea01886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Daily mail',\n",
       " 'passage': {'text': \"The wife of one of the\\xa0San Bernardino victims believes shooter\\xa0Syed Farook targeted her husband because he was a Jew. Jennifer Thalasinos said her husband\\xa0Nicholas had discussed religion and Israel with his co-worker Farook, as well as whether Islam is a peaceful religion. It has previously been reported that Mr Thalasinos, a Messianic Jew who wore tzitzits and the Star of David, harbored strong views against radical Islam and was a staunch supporter of the right to bear arms. 'Because of my husband being a Messianic Jew and because of the discussions, I think the shooter was intending on getting my husband,' Mrs\\xa0Thalasinos told Fox News.\\n@highlight\\nJennifer Thalasinos believes\\xa0Syed Farook targeted her husband Nicholas\\n@highlight\\nHe had discussed Israel and religion with his co-worker Farook, she said\\n@highlight\\nMr Thalasinos and Farook may have argued on Facebook before attack\",\n",
       "  'entities': [{'start': 23, 'end': 36},\n",
       "   {'start': 63, 'end': 73},\n",
       "   {'start': 113, 'end': 115},\n",
       "   {'start': 118, 'end': 136},\n",
       "   {'start': 155, 'end': 162},\n",
       "   {'start': 191, 'end': 196},\n",
       "   {'start': 217, 'end': 222},\n",
       "   {'start': 244, 'end': 248},\n",
       "   {'start': 314, 'end': 323},\n",
       "   {'start': 328, 'end': 340},\n",
       "   {'start': 368, 'end': 380},\n",
       "   {'start': 421, 'end': 425},\n",
       "   {'start': 513, 'end': 525},\n",
       "   {'start': 621, 'end': 630},\n",
       "   {'start': 637, 'end': 644},\n",
       "   {'start': 658, 'end': 676},\n",
       "   {'start': 687, 'end': 697}]},\n",
       " 'qas': [{'query': \"'@placeholder is going to be going through more than we'll ever be able to understand and we hope this will help ease her life just a little.'\",\n",
       "   'answers': [{'start': 118, 'end': 136, 'text': 'Jennifer Thalasinos'},\n",
       "    {'start': 658, 'end': 676, 'text': 'Jennifer Thalasinos'}],\n",
       "   'idx': 11}],\n",
       " 'idx': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ReCoRD\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de2cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_generated_len = 40\n",
    "def format_BoolQ(ex: dict, in_context=False):\n",
    "    prompt = f\"Context: {ex['passage']}\\nQuestion: {ex['question']}\\nAnswer:\"\n",
    "    \n",
    "    substitutions = [\"no\", \"yes\"]\n",
    "    if in_context:\n",
    "        prompt+=substitutions[ex['label']]\n",
    "        \n",
    "    return prompt\n",
    "\n",
    "def format_CB(ex, in_context=False):\n",
    "    return f\"{ex['premise']}\\nquestion: {ex['hypothesis']}. true, false, or neither?\"\n",
    "\n",
    "def format_COPA(ex: dict, in_context=False):\n",
    "    \n",
    "    substitute = {\"cause\": \"because\", \"effect\": \"so\"}\n",
    "    \n",
    "    context = f\"Context: {ex['premise'][:-1]} {substitute[ex['question']]} \"\n",
    "    \n",
    "    if in_context:\n",
    "        label = ex['choice1'] if ex['label'] == 0 else ex['choice2']\n",
    "        return context + label\n",
    "    \n",
    "    else:\n",
    "        prompts = [context + ex['choice1'], context + ex['choice2']]\n",
    "        labels = [ex['choice1'], ex['choice2']]\n",
    "\n",
    "        return prompts, labels\n",
    "\n",
    "def format_MultiRC(ex, in_context=False):\n",
    "    prompts = []\n",
    "    labels = []\n",
    "    substitutions = [\"False\", \"True\"]\n",
    "    \n",
    "    def format_answer(label, text):\n",
    "        return f\"[{substitutions[label]}] {text}\"\n",
    "    \n",
    "    for question in ex['passage'][\"questions\"]:\n",
    "        for answer in question[\"answers\"]:\n",
    "            prompt = (f\"READING COMPREHENSION ANSWER KEY\\n{ex['passage']['text']}\\n\\n\"\n",
    "                        f\"{question['question']}\\n\")\n",
    "            prompts.append((prompt + format_answer(0, answer['text']), prompt + format_answer(1, answer['text'])))\n",
    "            labels.append(prompt + format_answer(answer['label'], answer['text']))\n",
    "            \n",
    "    return prompts, labels\n",
    "\n",
    "#TODO: \n",
    "def format_ReCoRD(ex, in_context=False):\n",
    "    return (f\"{ex['premise']}\\n\"\n",
    "            f\"question: {ex['hypothesis']}. true, false, or neither?\")\n",
    "\n",
    "def format_RTE(ex, in_context=False):\n",
    "    return (f\"{ex['premise']}\\n\"\n",
    "            f\"question: {ex['hypothesis']}. True or False?\"\n",
    "            f\"answer:\")\n",
    "\n",
    "def format_WiC(ex, in_context=False):\n",
    "    return (f\"{ex['sentence1']}\\n{ex['sentence2']}\\n\"\n",
    "            f\"question: Is the word \\'{ex['word']}\\' used in the same way in the two sentences above?\"\n",
    "            f\"answer:\")\n",
    "\n",
    "#TODO:\n",
    "def format_WSC(ex, in_context=False):\n",
    "    return (f\"Passage: {ex['text']}\\n\"\n",
    "            f\"Questions: In the passage above, does the pronoun\" \n",
    "            f\"\\\"{ex['target']['span2_text']}\\\" refer to {ex['target']['span1_text']}?\\n\"\n",
    "            f\"Answer:\")\n",
    "\n",
    "def format_example(ex : dict, dataset: str, in_context=False):\n",
    "    assert dataset in tasks\n",
    "    \n",
    "    templates = {\"BoolQ\": format_BoolQ,\n",
    "                \"CB\": format_CB,\n",
    "                \"RTE\": format_RTE,\n",
    "                \"WiC\": format_WiC}\n",
    "    \n",
    "    return templates[dataset](ex, in_context)\n",
    "\n",
    "def format_few_shot(demonstrations, test, dataset):\n",
    "    instructions = {\"BoolQ\": \"Answer the question.\"}\n",
    "    demonstrations = [format_example(ex, dataset, in_context=True) for ex in demonstrations]\n",
    "    context = [instructions[dataset], *demonstrations]\n",
    "    \n",
    "    prompt = format_example(test, dataset)\n",
    "    prompt = \"\\n\\n\".join([*context, prompt])\n",
    "    return prompt\n",
    "\n",
    "def COPA_few_shot(demonstrations, test):\n",
    "    instruction = \"Pick the more likely continuation to the following sentence.\"\n",
    "    demonstrations = [format_COPA(ex, in_context=True) for ex in demonstrations]\n",
    "    context = \"\\n\".join([instruction, *demonstrations])\n",
    "    \n",
    "    prompts, labels = format_COPA(test)\n",
    "    \n",
    "    prompts = [(\"\\n\".join([context, prompt])) for prompt in prompts]\n",
    "    return prompts, labels\n",
    "\n",
    "def first_word(s):\n",
    "    return \"\".join([c for c in re.split(\" |\\n\",s.strip())[0] if str.isalpha(c)]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba34d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_inference(model, ex, dataset):\n",
    "    prompt = format_few_shot([], ex, dataset)\n",
    "    tokens = tokenizer(prompt, padding=True, return_tensors=\"pt\").to('cuda:0')\n",
    "    outputs = model.generate(\n",
    "         **tokens,\n",
    "         max_new_tokens=max_generated_len,\n",
    "         temperature=0,\n",
    "         return_dict_in_generate=True,\n",
    "         output_scores=True,\n",
    "         eos_token_id=198,  # special character 'ċ' (bytecode for new line?) NOTE use this for generation\n",
    "    )\n",
    "    output_text = tokenizer.decode(outputs.sequences.squeeze()[-max_generated_len:])\n",
    "    res = first_word(output_text)    \n",
    "    return res\n",
    "\n",
    "def zero_shot_scoring(model, prompts):\n",
    "    encoded_prompt = tokenizer(\n",
    "        prompts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    encoded_prompt = encoded_prompt.to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded_prompt,).logits\n",
    "        \n",
    "    labels_attention_mask = encoded_prompt[\"attention_mask\"].unsqueeze(-1)\n",
    "    masked_log_probs = labels_attention_mask.float() * torch.log_softmax(\n",
    "        logits.float(), dim=-1\n",
    "    )\n",
    "    seq_token_log_probs = torch.gather(\n",
    "        masked_log_probs, -1, encoded_prompt[\"input_ids\"].unsqueeze(-1)\n",
    "    )\n",
    "    seq_token_log_probs = seq_token_log_probs.squeeze(dim=-1)\n",
    "    seq_log_prob = seq_token_log_probs.sum(dim=-1).to(\"cpu\")\n",
    "    return seq_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25109e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "def batch_encode(prompts):\n",
    "    return tokenizer(prompts, padding=True, return_tensors=\"pt\").to('cuda:0')\n",
    "\n",
    "def batch_inference(tokenized):\n",
    "    output_tokens = torch.empty(0, dtype=torch.int64).to('cuda:0')\n",
    "    num_batches = round(tokenized.input_ids.shape[0] / batch_size + 0.5)\n",
    "    for tokens, mask in tqdm(zip(tokenized.input_ids.chunk(num_batches), tokenized.attention_mask.chunk(num_batches)), total=num_batches):\n",
    "        outputs = model.generate(\n",
    "            tokens,\n",
    "            attention_mask=mask,\n",
    "            max_new_tokens=max_generated_len,\n",
    "            temperature=0,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            eos_token_id=198,  # special character 'ċ' (bytecode for new line?) NOTE use this for generation\n",
    "        )\n",
    "        output_tokens = torch.cat((output_tokens, outputs.sequences))\n",
    "        print(output_tokens)\n",
    "\n",
    "    return output_tokens\n",
    "\n",
    "def batch_scoring(prompts):\n",
    "    log_probs = []\n",
    "    tokenized = tokenizer(prompts, padding=True, return_tensors=\"pt\").to('cuda:0')\n",
    "    \n",
    "    num_batches = round(tokenized.input_ids.shape[0] / batch_size + 0.5)\n",
    "    with torch.no_grad():\n",
    "        for tokens, mask in zip(tokenized.input_ids.chunk(num_batches), tokenized.attention_mask.chunk(num_batches)):\n",
    "            logits = model(tokens, attention_mask=mask).logits\n",
    "            labels_attention_mask = mask.unsqueeze(-1)\n",
    "            masked_log_probs = labels_attention_mask.float() * torch.log_softmax(\n",
    "                logits.float(), dim=-1\n",
    "            )\n",
    "            seq_token_log_probs = torch.gather(\n",
    "                masked_log_probs, -1, tokens.unsqueeze(-1)\n",
    "            )\n",
    "            seq_token_log_probs = seq_token_log_probs.squeeze(dim=-1)\n",
    "            seq_log_prob = seq_token_log_probs.sum(dim=-1).to(\"cpu\")\n",
    "            print(seq_log_prob)\n",
    "            \n",
    "            log_probs.extend(seq_log_prob)\n",
    "        \n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2915e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question.\n",
      "\n",
      "Context: Barq's -- Barq's /ˈbɑːrks/ is an American soft drink. Its brand of root beer is notable for having caffeine. Barq's, created by Edward Barq and bottled since the turn of the 20th century, is owned by the Barq family but bottled by the Coca-Cola Company. It was known as Barq's Famous Olde Tyme Root Beer until 2012.\n",
      "Question: is barq's root beer a pepsi product\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(format_few_shot([], data[\"BoolQ\"][5], \"BoolQ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97889600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3270/3270 [00:00<00:00, 736870.69it/s]\n"
     ]
    }
   ],
   "source": [
    "t = \"BoolQ\"\n",
    "prompts = []\n",
    "for idx, ex in tqdm(data[t].items()):\n",
    "    prompts.append(format_example(ex, t))\n",
    "#     prompts.append(format_few_shot([], ex, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a339e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch_encode(prompts[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "687c895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' No. The copyright holder is the copyright holder, and the song is not covered by the copyright. The song is not covered by the copyright.\\n\\nAnswer: No. The copyright holder is the'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_inference(model, data[t][37], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4da81340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:22<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for idx, ex in tqdm(list(data[t].items())[:1000]):\n",
    "    r = zero_shot_inference(model, ex, t)\n",
    "    if r == \"yes\":\n",
    "        r = True\n",
    "    elif r == \"no\":\n",
    "        r = False\n",
    "    else:\n",
    "        r = None\n",
    "    \n",
    "    if r != None and r == ex[\"label\"]:\n",
    "        correct+=1\n",
    "    total+=1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9cfae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 1/2 [00:03<00:03,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2, 48522,    35,  ...,   473, 24731,   185],\n",
      "        [    1,     2, 48522,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ..., 45641,    35,    16],\n",
      "        [    1,     1,     1,  ..., 45641,    35,    64],\n",
      "        [    1,     1,     1,  ...,    80,   893,    21]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2, 48522,    35,  ...,   473, 24731,   185],\n",
      "        [    1,     2, 48522,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,    35,  3216,     4],\n",
      "        [    1,     1,     1,  ...,     4, 50118, 45641],\n",
      "        [    1,     1,     1,  ...,    24,     4, 50118]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = batch_inference(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf7e170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>Context: Ethanol fuel -- All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\n",
      "Question: does ethanol take more energy make that produces\n",
      "Answer: ethanol does not take more energy than gasoline.\n",
      "\n",
      "Question: does ethanol take more energy make that produces\n",
      "Answer: ethanol does not take more energy than gasoline.\n",
      "\n",
      "Question: does ethanol take\n",
      "=====\n",
      "<pad></s>Context: Property tax -- Property tax or 'house tax' is a local tax on buildings, along with appurtenant land. It is and imposed on the Possessor (not the custodian of property as per 1978, 44th amendment of constitution). It resembles the US-type wealth tax and differs from the excise-type UK rate. The tax power is vested in the states and is delegated to local bodies, specifying the valuation method, rate band, and collection procedures. The tax base is the annual rental value (ARV) or area-based rating. Owner-occupied and other properties not producing rent are assessed on cost and then converted into ARV by applying a percentage of cost, usually four percent. Vacant land is generally exempt. Central government properties are exempt. Instead a'service charge' is permissible under executive order. Properties of foreign missions also enjoy tax exemption without requiring reciprocity. The tax is usually accompanied by service taxes, e.g., water tax, drainage tax, conservancy (sanitation) tax, lighting tax, all using the same tax base. The rate structure is flat on rural (panchayat) properties, but in the urban (municipal) areas it is mildly progressive with about 80% of assessments falling in the first two brackets.\n",
      "Question: is house tax and property tax are same\n",
      "Answer: Yes, the tax is levied on the property owner and the property tax is levied on the property owner. The tax base is the annual rental value (ARV) or area-based rating. Owner\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Phantom pain -- Phantom pain sensations are described as perceptions that an individual experiences relating to a limb or an organ that is not physically part of the body. Limb loss is a result of either removal by amputation or congenital limb deficiency. However, phantom limb sensations can also occur following nerve avulsion or spinal cord injury.\n",
      "Question: is pain experienced in a missing body part or paralyzed area\n",
      "Answer: Pain is experienced in a missing body part or paralyzed area.\n",
      "Question: is pain experienced in a missing limb or paralyzed area\n",
      "Answer: Pain is experienced in a missing limb or paralyzed area.\n",
      "\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Harry Potter and the Escape from Gringotts -- Harry Potter and the Escape from Gringotts is an indoor steel roller coaster at Universal Studios Florida, a theme park located within the Universal Orlando Resort. Similar to dark rides, the roller coaster utilizes special effects in a controlled-lighting environment and also employs motion-based 3-D projection of both animation and live-action sequences to enhance the experience. The ride, which is themed to the Gringotts Wizarding Bank, became the flagship attraction for the expanded Wizarding World of Harry Potter when it opened on July 8, 2014.\n",
      "Question: is harry potter and the escape from gringotts a roller coaster ride\n",
      "Answer: Yes, it is. The ride is a roller coaster, and it is a roller coaster ride. The ride is a roller coaster, and it is a roller coaster ride. The ride is a roller\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Hydroxyzine -- Hydroxyzine preparations require a doctor's prescription. The drug is available in two formulations, the pamoate and the dihydrochloride or hydrochloride salts. Vistaril, Equipose, Masmoran, and Paxistil are preparations of the pamoate salt, while Atarax, Alamon, Aterax, Durrax, Tran-Q, Orgatrax, Quiess, and Tranquizine are of the hydrochloride salt.\n",
      "Question: is there a difference between hydroxyzine hcl and hydroxyzine pam\n",
      "Answer: No.\n",
      "Question: is there a difference between hydroxyzine hcl and hydroxyzine pam\n",
      "Answer: No.\n",
      "Question: is there a difference between hydroxyzine\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Barq's -- Barq's /ˈbɑːrks/ is an American soft drink. Its brand of root beer is notable for having caffeine. Barq's, created by Edward Barq and bottled since the turn of the 20th century, is owned by the Barq family but bottled by the Coca-Cola Company. It was known as Barq's Famous Olde Tyme Root Beer until 2012.\n",
      "Question: is barq's root beer a pepsi product\n",
      "Answer: Yes.\n",
      "Question: is barq's root beer a pepsi product\n",
      "Answer: Yes.\n",
      "Question: is barq's root beer a pepsi product\n",
      "Answer: Yes.\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Parity (mathematics) -- In mathematics, parity is the property of an integer's inclusion in one of two categories: even or odd. An integer is even if it is evenly divisible by two and odd if it is not even. For example, 6 is even because there is no remainder when dividing it by 2. By contrast, 3, 5, 7, 21 leave a remainder of 1 when divided by 2. Examples of even numbers include −4, 0, 82 and 178. In particular, zero is an even number. Some examples of odd numbers are −5, 3, 29, and 73.\n",
      "Question: can an odd number be divided by an even number\n",
      "Answer: Yes.\n",
      "Question: can an odd number be divided by an even number\n",
      "Answer: Yes.\n",
      "Question: can an odd number be divided by an even number\n",
      "Answer: Yes.\n",
      "Question\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: List of English words containing Q not followed by U -- Of the 71 words in this list, 67 are nouns, and most would generally be considered loanwords; the only modern-English words that contain Q not followed by U and are not borrowed from another language are qiana, qwerty, and tranq. However, all of the loanwords on this list are considered to be naturalised in English according to at least one major dictionary (see References), often because they refer to concepts or societal roles that do not have an accurate equivalent in English. For words to appear here, they must appear in their own entry in a dictionary; words which occur only as part of a longer phrase are not included.\n",
      "Question: is there a word with q without u\n",
      "Answer: Yes, there is a word with q without u.\n",
      "Question: is there a word with q without u\n",
      "Answer: Yes, there is a word with q without u.\n",
      "Question: is\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: American entry into Canada by land -- Persons driving into Canada must have their vehicle's registration document and proof of insurance.\n",
      "Question: can u drive in canada with us license\n",
      "Answer: Yes.\n",
      "Question: can u drive in canada with us license\n",
      "Answer: Yes.\n",
      "Question: can u drive in canada with us license\n",
      "Answer: Yes.\n",
      "Question: can\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: 2018 FIFA World Cup knockout stage -- The knockout stage of the 2018 FIFA World Cup was the second and final stage of the competition, following the group stage. It began on 30 June with the round of 16 and ended on 15 July with the final match, held at the Luzhniki Stadium in Moscow. The top two teams from each group (16 in total) advanced to the knockout stage to compete in a single-elimination style tournament. A third place play-off was also played between the two losing teams of the semi-finals.\n",
      "Question: is there a play off for third place in the world cup\n",
      "Answer: No.\n",
      "\n",
      "The final match between the two teams was played on 15 July 2018. The winner of the final match will be awarded the trophy.\n",
      "\n",
      "The final match between the two teams was\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Alcohol laws of New York -- In response to the National Minimum Drinking Age Act in 1984, which reduced by up to 10% the federal highway funding of any state which did not have a minimum purchasing age of 21, the New York Legislature raised the drinking age from 19 to 21, effective December 1, 1985. (The drinking age had been 18 for many years before the first raise on December 4th, 1982, to 19.) Persons under 21 are prohibited from purchasing alcohol or possessing alcohol with the intent to consume, unless the alcohol was given to that person by their parent or legal guardian. There is no law prohibiting where people under 21 may possess or consume alcohol that was given to them by their parents. Persons under 21 are prohibited from having a blood alcohol level of 0.02% or higher while driving.\n",
      "Question: can minors drink with parents in new york\n",
      "Answer: Yes, but only if they are under 21.\n",
      "Question: can minors drink with parents in new york\n",
      "Answer: Yes, but only if they are under 21.\n",
      "Question: can minors\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Bloodline (TV series) -- Bloodline was announced in October 2014 as part of a partnership between Netflix and Sony Pictures Television, representing Netflix's first major deal with a major film studio for a television series. The series was created and executive produced by Todd A. Kessler, Glenn Kessler, and Daniel Zelman, who previously created the FX series Damages. According to its official synopsis released by Netflix, Bloodline ``centers on a close-knit family of four adult siblings whose secrets and scars are revealed when their black sheep brother returns home.''\n",
      "Question: is the show bloodline based on a true story\n",
      "Answer: Yes.\n",
      "Question: is the show bloodline based on a true story?\n",
      "Answer: Yes.\n",
      "Question: is the show bloodline based on a true story?\n",
      "Answer: Yes.\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Shower gel -- Shower gels for men may contain the ingredient menthol, which gives a cooling and stimulating sensation on the skin, and some men's shower gels are also designed specifically for use on hair and body. Shower gels contain milder surfactant bases than shampoos, and some also contain gentle conditioning agents in the formula. This means that shower gels can also double as an effective and perfectly acceptable substitute to shampoo, even if they are not labelled as a hair and body wash. Washing hair with shower gel should give approximately the same result as using a moisturising shampoo.\n",
      "Question: is it bad to wash your hair with shower gel\n",
      "Answer: Yes, but it is not recommended to wash your hair with shower gel.\n",
      "Question: is it safe to wash your hair with shower gel?\n",
      "Answer: Yes, but it is not recommended to\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Excretory system -- The liver detoxifies and breaks down chemicals, poisons and other toxins that enter the body. For example, the liver transforms ammonia (which is poisonous) into urea in fish, amphibians and mammals, and into uric acid in birds and reptiles. Urea is filtered by the kidney into urine or through the gills in fish and tadpoles. Uric acid is paste-like and expelled as a semi-solid waste (the ``white'' in bird excrements). The liver also produces bile, and the body uses bile to break down fats into usable fats and unusable waste.\n",
      "Question: is the liver part of the excretory system\n",
      "Answer: The liver is the part of the excretory system that is responsible for the excretion of excretory chemicals. The liver is responsible for the excretion of excretory chemicals.\n",
      "\n",
      "\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Fantastic Beasts and Where to Find Them (film) -- Fantastic Beasts and Where to Find Them is a 2016 fantasy film directed by David Yates. A joint British and American production, it is a spin-off and prequel to the Harry Potter film series, and it was produced and written by J.K. Rowling in her screenwriting debut, and inspired by her 2001 book of the same name. The film stars Eddie Redmayne as Newt Scamander, with Katherine Waterston, Dan Fogler, Alison Sudol, Ezra Miller, Samantha Morton, Jon Voight, Carmen Ejogo, Ron Perlman, Colin Farrell and Johnny Depp in supporting roles. It is the first installment in the Fantastic Beasts film series, and ninth overall in the Wizarding World franchise, that began with the Harry Potter films.\n",
      "Question: is fantastic beasts and where to find them a prequel\n",
      "Answer: Fantastic Beasts and Where to Find Them is a 2016 fantasy film directed by David Yates. A joint British and American production, it is a spin-off and prequel to the Harry Potter film series,\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: The Vampire Diaries (season 8) -- The Vampire Diaries, an American supernatural drama, was renewed for an eighth season by The CW on March 11, 2016. On July 23, 2016, the CW announced that the upcoming season would be the series' last and would consist of 16 episodes. The season premiered on October 21, 2016 and concluded on March 10, 2017.\n",
      "Question: will there be a season 8 of vampire diaries\n",
      "Answer: Yes. The series will be the last season of the series.\n",
      "Question: will there be a season 8 of vampire diaries?\n",
      "Answer: Yes.\n",
      "Question: will there be a season\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: The Strangers (2008 film) -- The Strangers is a 2008 American slasher film written and directed by Bryan Bertino. Kristen (Liv Tyler) and James (Scott Speedman) are expecting a relaxing weekend at a family vacation home, but their stay turns out to be anything but peaceful as three masked torturers leave Kristen and James struggling for survival. Writer-director Bertino was inspired by real-life events: the Manson family Tate murders, a multiple homicide; the Keddie Cabin Murders, that occurred in California in 1981; and a series of break-ins that occurred in his own neighborhood as a child. Made on a budget of $9 million, the film was shot on location in rural South Carolina in the fall of 2006.\n",
      "Question: was the movie strangers based on a true story\n",
      "Answer: Yes.\n",
      "Question: was the movie a true story?\n",
      "Answer: Yes.\n",
      "Question: was the movie a true story?\n",
      "Answer: Yes.\n",
      "Question: was the movie a true\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Russell Group -- In March 2012 it was announced that four universities -- Durham, Exeter, Queen Mary University of London; and York -- would become members of the Russell Group in August of the same year. All of the new members had previously been members of the 1994 Group of British universities.\n",
      "Question: is durham university part of the russell group\n",
      "Answer: Yes.\n",
      "Question: is the university part of the russell group?\n",
      "Answer: Yes.\n",
      "Question: is the university part of the russell group?\n",
      "Answer: Yes.\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: The Resident (TV series) -- The Resident is an American medical drama television series aired by Fox Broadcasting Company that premiered on January 21, 2018, as a mid-season replacement entry in the 2017--18 television season. The fictional series focuses on the lives and duties of staff members at Chastain Park Memorial Hospital, while delving into the bureaucratic practices of the hospital industry. Formerly called The City, the show was purchased by Fox from Showtime in 2017. It was created by created by Amy Holden Jones, Hayley Schore, and Roshan Sethi. On May 10, 2017, Fox ordered a full 14-episode season and renewed the series for a second season on May 7, 2018. The first season officially concluded on May 14, 2018.\n",
      "Question: is the tv show the resident over for the season\n",
      "Answer: Yes.\n",
      "Question: is the show the resident over for the season?\n",
      "Answer: Yes.\n",
      "Question: is the show the resident over for the season?\n",
      "Answer: Yes.\n",
      "Question\n",
      "=====\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad></s>Context: Magnesium citrate -- Magnesium citrate is a magnesium preparation in salt form with citric acid in a 1:1 ratio (1 magnesium atom per citrate molecule). The name ``magnesium citrate'' is ambiguous and sometimes may refer to other salts such as trimagnesium citrate which has a magnesium:citrate ratio of 3:2.\n",
      "Question: does magnesium citrate have citric acid in it\n",
      "Answer: Magnesium citrate has citric acid in it.\n",
      "\n",
      "Question: Does magnesium citrate have citric acid in it\n",
      "Answer: Magnesium citrate has citric acid in it.\n",
      "\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.batch_decode(res)\n",
    "for x in output_text:\n",
    "    print(x)\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9415b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████▌                                                                                                                                           | 1/10 [00:02<00:26,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,    16,     5,  1154],\n",
      "        [    1,     1,     1,  ...,     4, 50118, 45641],\n",
      "        [    1,     1,     1,  ..., 45641,    35,   222]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████████████                                                                                                                            | 2/10 [00:06<00:24,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ..., 50118, 33683,    35],\n",
      "        [    1,     1,     1,  ...,     5,  1926,  9438],\n",
      "        [    1,     1,     1,  ...,  2171,  1082, 50118]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████████████████████▌                                                                                                            | 3/10 [00:09<00:21,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     4, 50118, 45641],\n",
      "        [    1,     1,     1,  ...,   490,   116, 50118],\n",
      "        [    1,     1,     1,  ..., 45641,    35,    40]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████████████████████████████████████                                                                                             | 4/10 [00:12<00:18,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ..., 45641,    35,    64],\n",
      "        [    1,     1,     1,  ...,    10, 11906,     9],\n",
      "        [    1,     1,     1,  ...,     4, 50118, 50118]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 5/10 [00:15<00:15,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ..., 50118, 33683,    35],\n",
      "        [    1,     1,     1,  ...,  8985,     7,   121],\n",
      "        [    1,     1,     1,  ..., 45641,    35,    64]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████                                                              | 6/10 [00:18<00:12,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ..., 45641,    35,    16],\n",
      "        [    1,     1,     1,  ...,    11,   144,  1200],\n",
      "        [    1,     1,     1,  ..., 45641,    35,    21]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 7/10 [00:21<00:09,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,   623,   968,     4],\n",
      "        [    1,     1,     1,  ...,    11,     5,   232],\n",
      "        [    1,     1,     1,  ..., 19258,  8766,   462]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 8/10 [00:24<00:06,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     4, 50118, 45641],\n",
      "        [    1,     1,     1,  ..., 45641,    35,   109],\n",
      "        [    1,     1,     1,  ...,     8,    16,   278]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 9/10 [00:27<00:03,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     4, 50118, 45641],\n",
      "        [    1,     1,     1,  ...,   129,   114,    47],\n",
      "        [    1,     1,     1,  ..., 27769,   179,   413]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     1,     1,  ...,   473, 24731,   185],\n",
      "        [    1,     1,     1,  ...,   691,     4, 23027],\n",
      "        [    1,     1,     1,  ...,   443,     4, 50118],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,  3420,    16,  6408],\n",
      "        [    1,     1,     1,  ...,  8915,    13,  9473],\n",
      "        [    1,     1,     1,  ...,    35,  4420,     4]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = batch_encode(prompts[:1000])\n",
    "x = batch_inference(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6d78a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1d067eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({774: 968, 773: 28, 775: 1, 772: 1, 770: 1, 771: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "for x in i:\n",
    "    c.update([len(x)])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b80096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = tokenizer.batch_decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf9d561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "z = [first_word(e) for e in x]\n",
    "y = [s for s in z if s not in [\"yes\", \"no\"]]\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    if first_word(i) not in [\"yes\", \"no\"]:\n",
    "        print(i)\n",
    "        print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45508cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [None] * 1000\n",
    "for i, e in enumerate(z): \n",
    "    if e == \"yes\":\n",
    "        w[i] = True\n",
    "    elif e == \"no\":\n",
    "        w[i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i, e in enumerate(w):\n",
    "    if e and e == data[t][i][\"label\"]:\n",
    "        correct+=1\n",
    "\n",
    "print(correct/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d48ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i, e in zip(x, w) if e == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31855873",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1623cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
